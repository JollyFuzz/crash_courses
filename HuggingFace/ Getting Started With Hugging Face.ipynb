{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03ad2a3",
   "metadata": {},
   "source": [
    "# Getting Started With Hugging Face in 15 Minutes | Transformers, Pipeline, Tokenizer, Models\n",
    "Источник: https://www.youtube.com/watch?v=QEaBAZQCtwE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb6140",
   "metadata": {},
   "source": [
    "# Установка \n",
    "\n",
    "Для начала работы достаточно установить библиотеку transformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a860d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40cd9c9",
   "metadata": {},
   "source": [
    "# Пайплайны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6df98",
   "metadata": {},
   "source": [
    "Пайплайн с моделью по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ddd64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.7705543637275696}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "res = classifier(\"Ух, как я счастлив\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b1584",
   "metadata": {},
   "source": [
    "Пример посложнее с различными параметрами модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5681130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'В этом курсе, мы будем разбирать как это сделатьа Влек курсе, этом курсе, мы будем издевет курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом курсе, этом ку'}, {'generated_text': 'В этом курсе, мы будем разбирать как это сделатьо Г в блежамьский проствупано го со проствупано а кортите, и жезаго сопох даферание тележамь и на разго в блежамьский проствупано евствупано в и зго в в блежамьский проствупано бый проствупано в блежамьский проствупано го бый прос'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "res = generator(\n",
    "    \"В этом курсе, мы будем разбирать как это сделать\", \n",
    "    max_length=30, \n",
    "    num_return_sequences=2\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dc77d0",
   "metadata": {},
   "source": [
    "Пробрасываем модель и токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f510d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.7705543637275696}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "res = classifier(\"Ух, как я счастлив\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6118d64",
   "metadata": {},
   "source": [
    "Как работает токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "539452af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2478, 1037, 10938, 2121, 2897, 2003, 3722, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['using', 'a', 'transform', '##er', 'network', 'is', 'simple']\n",
      "[2478, 1037, 10938, 2121, 2897, 2003, 3722]\n",
      "using a transformer network is simple\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Using a Transformer network is simple\"\n",
    "res = tokenizer(sequence)\n",
    "print(res)\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "\n",
    "decoded_string = tokenizer.decode(ids)\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c43f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
